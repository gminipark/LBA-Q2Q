{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023-present the HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "# Fixed RandomSeed\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'Salesforce/instructblip-flan-t5-xl'\n",
    "cache_dir = \"./\" + model_name_or_path.split('/')[-1]\n",
    "\n",
    "dtype = torch.float16\n",
    "\n",
    "# We load our model and processor using `transformers`\n",
    "processor = InstructBlipProcessor.from_pretrained(model_name_or_path,cache_dir=cache_dir)\n",
    "model = InstructBlipForConditionalGeneration.from_pretrained(model_name_or_path,cache_dir=cache_dir, torch_dtype=dtype)\n",
    "\n",
    "# Get our peft model and print the number of trainable parameters\n",
    "print([name for name,p in model.named_parameters()])\n",
    "\n",
    "for param in model.vision_model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = Model(model)\n",
    "\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"csv\", data_files={\"train\" : \"./train_6400_same_true_aug_v2.csv\"}, split=\"train\")\n",
    "test_dataset = load_dataset(\"csv\", data_files={\"test\" : \"./test_367_same_true_v2.csv\"}, split=\"test\")\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTextClassificationDataset(Dataset):\n",
    "    def __init__(self, dataset, processor):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        image = Image.open(\"./images/\"+str(item['image_id'])+\".jpg\")\n",
    "      \n",
    "        # remove batch dimension\n",
    "        encoding = {}\n",
    "        encoding['image']=image\n",
    "        encoding[\"text\"] = \"Given an ambiguous quesiton, an ambigous entity and an intermediate question, your task is to classify whether the intermediate question clarifies the ambigious entity in the ambiguous quesiton.\" # The ambiguous entity means that it appears multiple times in the image and cannot be distinctly identified. A good intermediate question is one that clarify a specific entity among same entities. Additionaly, A bad intermediate question is one that can't determine one entity among the entities through the intermediate quesiton.  If you think the given intermediate question is good, indicate it by answering \\\"Yes\\\". Otherwise, answer \\\"No\\\".There are only two types of answers possible: \\\"Yes\\\" and \\\"No\\\".\"\n",
    "        encoding[\"text\"] = encoding[\"text\"] + \" Ambiguous question: \" + item[\"ambiguous_question\"] + \"Ambiguous entity: \" + item[\"ambiguous_entity\"] + \" Intermediate question: \" + item[\"intermediate_question\"] + \" Short answer:\"\n",
    "        \n",
    "        # encoding[\"text\"] = \"Ambiguous question: \" + item[\"ambiguous_question\"] +\" Ambigous entity: \" + item[\"ambiguous_entity\"] + \" Intermediate question: \" + item[\"intermediate_question\"] # + \" Intermediate answer: \" + item[\"intermediate_answer\"]\n",
    "        # encoding[\"text\"] = encoding['text'] + \" Is the intermediate question effective to clarify the ambiguous entity in the ambiguous question? Classify yes or no. Short answer: \"\n",
    "        \n",
    "        \n",
    "        if 'effectiveness' in item.keys():\n",
    "            encoding['label'] = \"yes\" if item['effectiveness'] == \"O\" else 'no' # torch.tensor(1) if item['effectiveness'] == \"O\" else torch.tensor(0)\n",
    "        elif 'labels' in item.keys():\n",
    "            encoding['label'] =  \"Yes\" if item['labels'] == \"O\" else 'No' # item['labels']\n",
    "        else:\n",
    "            encoding['label'] = encoding['text']\n",
    "\n",
    "        \n",
    "        if \"t5\" in self.processor.tokenizer.name_or_path:\n",
    "            encoding['decoder_input_ids'] = torch.tensor([self.processor.tokenizer.pad_token_id])\n",
    "        \n",
    "        inputs = processor(images=encoding['image'],text=encoding['text'],return_tensors=\"pt\", max_length=128, padding='max_length' ,truncation=True)\n",
    "        encoding.pop('image')\n",
    "        encoding.pop('text')\n",
    "        encoding.update(inputs)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "def collator(batch):\n",
    "    # pad the input_ids and attention_mask\n",
    "    processed_batch = {}\n",
    "    for key in batch[0].keys():       \n",
    "        if key == \"label\":\n",
    "            labels = processor.tokenizer([example['label'] for example in batch], padding='max_length', add_special_tokens=True, return_tensors='pt')\n",
    "            processed_batch['labels'] = labels['input_ids']\n",
    "        else:\n",
    "            processed_batch[key] = torch.stack([example[key].squeeze() for example in batch])\n",
    "     \n",
    "    return processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = ImageTextClassificationDataset(train_dataset, processor)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=1, collate_fn=collator)\n",
    "\n",
    "test_dataset = ImageTextClassificationDataset(test_dataset, processor)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=4, collate_fn=collator)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "epoch_loss_list = []\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# with open(\"./ambiguous_questions_test.csv\", 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     lines = [line for line in reader]\n",
    "\n",
    "def compute_acc(predictions, references):\n",
    "    \n",
    "    total_len = len(predictions)\n",
    "    same_count = 0\n",
    "    for prediction, reference in zip(predictions, references):\n",
    "        if prediction == reference:\n",
    "            same_count += 1\n",
    "    \n",
    "    return same_count / total_len\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    epoch_loss = []\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        for key in batch.keys():\n",
    "            batch[key] = batch[key].to(device)\n",
    "            \n",
    "        if \"t5\" in model_name_or_path:\n",
    "            decoder_input_ids = batch.pop(\"decoder_input_ids\").to(device)\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        else:\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        #print(labels)\n",
    "        #print(outputs)\n",
    "        \n",
    "        # loss = criterion(outputs, labels)\n",
    "        loss = outputs.loss\n",
    "        #print(loss.item())\n",
    "        #loss = torch.mean(outputs)\n",
    "        \n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #if idx % 10 == 0:\n",
    "        #    generated_output = model.generate(pixel_values=pixel_values, input_ids=input_ids)\n",
    "        #    print(processor.batch_decode(generated_output, skip_special_tokens=True))\n",
    "    \n",
    "    print(np.mean(epoch_loss))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_outputs = []\n",
    "        gold_references = []\n",
    "        # metric = load(\"accuracy\")\n",
    "        for idx, batch in enumerate(tqdm(test_dataloader)):\n",
    "            for key in batch.keys():\n",
    "                batch[key] = batch[key].to(device)\n",
    "            \n",
    "            # if \"t5\" in model_name_or_path:\n",
    "            #     decoder_input_ids = batch.pop(\"decoder_input_ids\").to(device)\n",
    "            #     logits = model(pixel_values, input_ids, decoder_input_ids)\n",
    "            # else:\n",
    "            outputs = model.generate(**batch)\n",
    "            predictions = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            references = processor.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "            # metric.add_batch(predictions=predictions, references=references)\n",
    "            \n",
    "            epoch_outputs += predictions #processor.batch_decode(generated_output, skip_special_tokens=True)\n",
    "            gold_references += references\n",
    "            \n",
    "        #accuracy = metric.compute()\n",
    "        print(epoch_outputs[:10])\n",
    "        print(gold_references[:10])\n",
    "        print(compute_acc(epoch_outputs , gold_references))\n",
    "        \n",
    "    # with open (\"./test_{}.csv\".format(epoch), 'w') as f:\n",
    "        \n",
    "    #     writer = csv.writer(f)\n",
    "    #     for idx, line in enumerate(lines):\n",
    "    #         if idx == 0:\n",
    "    #             writer.writerow(line)\n",
    "    #         else:\n",
    "    #             line.append(epoch_outputs[idx-1])\n",
    "    #             writer.writerow(line)\n",
    "                \n",
    "    model.train()            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
