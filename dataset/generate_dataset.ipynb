{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl_list = glob(\"./gqa_data/*.pkl\")\n",
    "\n",
    "with open(\"./gqa_data/created_data.pkl\" , \"rb\") as f:\n",
    "    pkl = pickle.load(f)\n",
    "    \n",
    "with open(\"./gqa_data/train_balanced_questions.json\") as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "#pprint(pkl['2354786'])\n",
    "\n",
    "pprint(pkl['2354786'][5])\n",
    "\n",
    "#print(questions['2354786'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./gqa_data/train_balanced_questions.json\") as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sceneGraphs/train_sceneGraphs.json\") as f:\n",
    "    sceneGraphs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_object_names(objects, related_objects, question):\n",
    "    \n",
    "    object_ids = {}\n",
    "    \n",
    "    question_annotated_objects = related_objects['question']\n",
    "    '''\n",
    "    for key, value in related_objects.items():\n",
    "    \n",
    "        object_ids[key] = set()\n",
    "        for start_idx, object_id  in value.items():\n",
    "            object_ids[key].add(object_id)\n",
    "    '''\n",
    "    object_ids['question'] = set()\n",
    "    for start_idx, object_id in question_annotated_objects.items():\n",
    "       \n",
    "        object_ids['question'].add(object_id)\n",
    "    \n",
    "    object_names = []\n",
    "    \n",
    "    related_object_dict = {}\n",
    "    related_object_ids = set()\n",
    "    related_object_names = set()\n",
    "    irrelated_object_dict = {}\n",
    "    \n",
    "    for key, object_ids in object_ids.items():\n",
    "        related_object_dict[key] = {}\n",
    "        for object_id in object_ids:\n",
    "            object = objects[object_id]\n",
    "            object_name = object['name']\n",
    "            if object_name in question:\n",
    "                related_object_dict[key][object_id] = object_name\n",
    "                related_object_ids.add(object_id)\n",
    "                related_object_names.add(object_name)\n",
    "    \n",
    "    for key, value in objects.items():\n",
    "        \n",
    "        object_name = value['name']\n",
    "        if not key in related_object_ids and object_name in related_object_names:\n",
    "            irrelated_object_dict[key] = object_name\n",
    "    \n",
    "    \n",
    "    return related_object_dict, irrelated_object_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(questions))\n",
    "\n",
    "ambiguous_questions = {}\n",
    "exsit_question_nums = 0\n",
    "\n",
    "for idx, (question_key, question_value) in tqdm(enumerate(questions.items())):\n",
    "    if idx < 1:\n",
    "        pprint(question_value)\n",
    "    #pprint(question_value)\n",
    "    if 'exist' in question_value['types']['detailed']:\n",
    "        exsit_question_nums += 1\n",
    "        # if exsit_question_nums < 5:\n",
    "        #    print(\"exist-question\\n\",question_value['question'])\n",
    "        continue\n",
    "    image_id = question_value['imageId']\n",
    "    #pprint(sceneGraphs[image_id])\n",
    "    sceneGraph=sceneGraphs[image_id]\n",
    "    related_objects = question_value['annotations']\n",
    "    objects = sceneGraph['objects']\n",
    "    \n",
    "    related_object_names, irrelated_object_names = get_related_object_names(objects, related_objects,question_value['question'] )\n",
    "    #names_set = set(names)\n",
    "    \n",
    "    #if len(names) != len(names_set):\n",
    "    if len(irrelated_object_names) > 0:\n",
    "        if len(ambiguous_questions.keys()) < 30:\n",
    "        #pprint(question_value)\n",
    "        #pprint(sceneGraphs[image_id])\n",
    "            print(image_id)\n",
    "            pprint(related_object_names)\n",
    "            pprint(irrelated_object_names)\n",
    "            print(question_value['question'])\n",
    "            print(question_value['fullAnswer'])\n",
    "            print(question_value['types']['detailed'])\n",
    "            print(\"---------------------------\")\n",
    "        #print('다름')\n",
    "        #break\n",
    "        question_value['irrelated_object_names'] = irrelated_object_names\n",
    "        ambiguous_questions[question_key] = question_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(questions.keys()))\n",
    "print(exsit_question_nums)\n",
    "print(len(ambiguous_questions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\",cache_dir=\"./blip2-flan-t5-xxl\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\", torch_dtype=torch.float16, cache_dir=\"./blip2-flan-t5-xxl\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = {}\n",
    "new_dataset_length = len(ambiguous_questions)\n",
    "for idx, (question_id, question_value) in tqdm(enumerate(ambiguous_questions.items()), total=new_dataset_length):\n",
    "    if idx == new_dataset_length:\n",
    "        break\n",
    "    \n",
    "    image_id = question_value['imageId']\n",
    "    img_file = './images/' + image_id + '.jpg' \n",
    "    raw_image = Image.open(img_file).convert('RGB')\n",
    "\n",
    "    question = \"Instructions: Given a picture, A question and a correct answer related the picture are provided.\\\n",
    "    The answer can be inferred from the picture. \\\n",
    "    The target(object) of question  which is existed in the picture is important key to infer the answer. (objects in question are bold) \\\n",
    "    The additional information of object related question is helpful for answer the question more correctly. \\\n",
    "    Therefore, our goal is to get new information related answer by asking a new question. \\\n",
    "    Write an additional question to help to answer the original question correctly.  \\\n",
    "    original question: \" + question_value['question'] + \" \" + \\\n",
    "    \"uncertain information: \" + list(question_value['irrelated_object_names'].values())[0] + \" \" + \\\n",
    "    \"answer: \" + question_value['fullAnswer'] + \" \" + \\\n",
    "    \"additional question: \"\n",
    "\n",
    "    if idx < 2:\n",
    "        print(question)\n",
    "\n",
    "    inputs = processor(raw_image, question, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    out = model.generate(**inputs)\n",
    "    additional_question = processor.decode(out[0], skip_special_tokens=True)\n",
    "    \n",
    "    question_value['addtional_question'] = additional_question\n",
    "    new_dataset[question_id] = question_value\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ambiguous_questions.json\", 'w') as f:\n",
    "    json.dump(new_dataset, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "with open(\"ambiguous_questions.json\", 'r') as f:\n",
    "    full_dataset  = json.load(f)\n",
    "\n",
    "dataset_sampling = {}\n",
    "\n",
    "full_list = list(full_dataset.items())\n",
    "np.random.seed(42)\n",
    "random_indexs = np.random.choice(range(0, len(full_list)), 200, replace = False)\n",
    "print(random_indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "train_list = [['question_id','question', 'answer', 'intermediate_question', 'ambiquous_object', 'image_id']]\n",
    "test_list = [['question_id','question', 'answer', 'intermediate_question', 'ambiquous_object', 'image_id']]\n",
    "for idx, q_idx in enumerate(random_indexs):\n",
    "    (key, value) = full_list[q_idx] \n",
    "    dataset_sampling[key] = value\n",
    "    original_q = value['question']\n",
    "    answer = value['fullAnswer']\n",
    "    ambiguous_object = list(value['irrelated_object_names'].values())[0]\n",
    "    intermediate_q = value[\"addtional_question\"]\n",
    "    image_id = value['imageId']\n",
    "    \n",
    "    if idx < 100:\n",
    "        train_list.append([q_idx, original_q, answer, intermediate_q, ambiguous_object, image_id])\n",
    "    else:\n",
    "        test_list.append([q_idx, original_q, answer, intermediate_q, ambiguous_object, image_id])\n",
    "    \n",
    "with open(\"ambiguous_questions_100_random.csv\", 'w') as f:\n",
    "#     json.dump(dataset_sampling, f, ensure_ascii=False)\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(train_list)\n",
    "    \n",
    "with open(\"ambiguous_questions_test.csv\", 'w') as f:\n",
    "#     json.dump(dataset_sampling, f, ensure_ascii=False)\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv',data_files={'train': \"./ambiguous_questions_train.csv\", 'test' : \"./ambiguous_questions_test.csv\"})\n",
    "\n",
    "print(dataset['train'])\n",
    "\n",
    "#with open(\"ambiguous_questions_100_random_label.csv\", 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "    \n",
    "#    for line in reader:\n",
    "#        print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "few_shot_examples = {}\n",
    "\n",
    "intermediate_questions =  pd.read_excel(\"intermediate_questions_samples_32.xlsx\", dtype={'qid' : str})\n",
    "\n",
    "with open(\"./ambiguous_questions_rebuilt.json\") as f:\n",
    "    ambiguous_questions = json.load(f)\n",
    "\n",
    "with open(\"./ambiguous_questions.json\") as f:\n",
    "    original_questions = json.load(f)\n",
    "\n",
    "print(len(ambiguous_questions))\n",
    "for idx in intermediate_questions.index:\n",
    "    intermediate_question_example = intermediate_questions.iloc[idx]\n",
    "    qid = intermediate_question_example['qid']\n",
    "\n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    \n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    intermediate_question = intermediate_question_example['intermediate question']\n",
    "    original_question_example = original_questions.pop(qid)\n",
    "    \n",
    "    few_shot_examples[qid] = original_question_example\n",
    "    few_shot_examples[qid]['ambiguous_question'] = ambiguous_question\n",
    "    few_shot_examples[qid]['intermediate_question'] = intermediate_question\n",
    "    few_shot_examples[qid].pop(\"addtional_question\")\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in few_shot_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in few_shot_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    few_shot_examples[qid]['question_entities'] = list(entities_list)\n",
    "   \n",
    "np.random.seed(42) \n",
    "test_keys = np.random.choice(list(original_questions.keys()), 32, replace=False)\n",
    "test_examples = {}\n",
    "\n",
    "for qid in test_keys:\n",
    "    original_questions[qid].pop(\"addtional_question\")\n",
    "    test_examples[qid] =  original_questions[qid]\n",
    "    \n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    \n",
    "    test_examples[qid][\"ambiguous_question\"] = ambiguous_question\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in test_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in test_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    test_examples[qid]['question_entities'] = list(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "test_examples_list = [{k:v}  for k,v in test_examples.items()]\n",
    "pprint(test_examples_list[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lba-kaist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
