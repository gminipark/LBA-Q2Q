{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023-present the HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b4c98d92954de12c\n",
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-b4c98d92954de12c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1a77b177f3431694f7b8459317b7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\" : \"./ambiguous_questions_train.csv\", \"test\" : \"./ambiguous_questions_test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5127fd3ea64d5480af6796295536fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamingo model initialized with 1384781840 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "from open_flamingo import create_model_and_transforms\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "    cross_attn_every_n_layers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_encoder.class_embedding', 'vision_encoder.positional_embedding', 'vision_encoder.proj', 'vision_encoder.conv1.weight', 'vision_encoder.ln_pre.weight', 'vision_encoder.ln_pre.bias', 'vision_encoder.transformer.resblocks.0.ln_1.weight', 'vision_encoder.transformer.resblocks.0.ln_1.bias', 'vision_encoder.transformer.resblocks.0.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.0.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.0.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.0.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.0.ln_2.weight', 'vision_encoder.transformer.resblocks.0.ln_2.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_1.weight', 'vision_encoder.transformer.resblocks.1.ln_1.bias', 'vision_encoder.transformer.resblocks.1.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.1.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.1.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.1.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.1.ln_2.weight', 'vision_encoder.transformer.resblocks.1.ln_2.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_1.weight', 'vision_encoder.transformer.resblocks.2.ln_1.bias', 'vision_encoder.transformer.resblocks.2.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.2.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.2.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.2.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.2.ln_2.weight', 'vision_encoder.transformer.resblocks.2.ln_2.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_1.weight', 'vision_encoder.transformer.resblocks.3.ln_1.bias', 'vision_encoder.transformer.resblocks.3.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.3.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.3.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.3.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.3.ln_2.weight', 'vision_encoder.transformer.resblocks.3.ln_2.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_1.weight', 'vision_encoder.transformer.resblocks.4.ln_1.bias', 'vision_encoder.transformer.resblocks.4.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.4.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.4.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.4.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.4.ln_2.weight', 'vision_encoder.transformer.resblocks.4.ln_2.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_1.weight', 'vision_encoder.transformer.resblocks.5.ln_1.bias', 'vision_encoder.transformer.resblocks.5.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.5.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.5.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.5.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.5.ln_2.weight', 'vision_encoder.transformer.resblocks.5.ln_2.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_1.weight', 'vision_encoder.transformer.resblocks.6.ln_1.bias', 'vision_encoder.transformer.resblocks.6.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.6.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.6.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.6.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.6.ln_2.weight', 'vision_encoder.transformer.resblocks.6.ln_2.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_1.weight', 'vision_encoder.transformer.resblocks.7.ln_1.bias', 'vision_encoder.transformer.resblocks.7.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.7.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.7.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.7.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.7.ln_2.weight', 'vision_encoder.transformer.resblocks.7.ln_2.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_1.weight', 'vision_encoder.transformer.resblocks.8.ln_1.bias', 'vision_encoder.transformer.resblocks.8.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.8.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.8.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.8.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.8.ln_2.weight', 'vision_encoder.transformer.resblocks.8.ln_2.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_1.weight', 'vision_encoder.transformer.resblocks.9.ln_1.bias', 'vision_encoder.transformer.resblocks.9.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.9.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.9.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.9.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.9.ln_2.weight', 'vision_encoder.transformer.resblocks.9.ln_2.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_1.weight', 'vision_encoder.transformer.resblocks.10.ln_1.bias', 'vision_encoder.transformer.resblocks.10.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.10.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.10.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.10.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.10.ln_2.weight', 'vision_encoder.transformer.resblocks.10.ln_2.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_1.weight', 'vision_encoder.transformer.resblocks.11.ln_1.bias', 'vision_encoder.transformer.resblocks.11.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.11.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.11.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.11.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.11.ln_2.weight', 'vision_encoder.transformer.resblocks.11.ln_2.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_1.weight', 'vision_encoder.transformer.resblocks.12.ln_1.bias', 'vision_encoder.transformer.resblocks.12.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.12.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.12.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.12.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.12.ln_2.weight', 'vision_encoder.transformer.resblocks.12.ln_2.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.12.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_1.weight', 'vision_encoder.transformer.resblocks.13.ln_1.bias', 'vision_encoder.transformer.resblocks.13.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.13.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.13.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.13.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.13.ln_2.weight', 'vision_encoder.transformer.resblocks.13.ln_2.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.13.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_1.weight', 'vision_encoder.transformer.resblocks.14.ln_1.bias', 'vision_encoder.transformer.resblocks.14.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.14.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.14.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.14.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.14.ln_2.weight', 'vision_encoder.transformer.resblocks.14.ln_2.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.14.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_1.weight', 'vision_encoder.transformer.resblocks.15.ln_1.bias', 'vision_encoder.transformer.resblocks.15.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.15.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.15.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.15.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.15.ln_2.weight', 'vision_encoder.transformer.resblocks.15.ln_2.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.15.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_1.weight', 'vision_encoder.transformer.resblocks.16.ln_1.bias', 'vision_encoder.transformer.resblocks.16.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.16.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.16.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.16.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.16.ln_2.weight', 'vision_encoder.transformer.resblocks.16.ln_2.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.16.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_1.weight', 'vision_encoder.transformer.resblocks.17.ln_1.bias', 'vision_encoder.transformer.resblocks.17.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.17.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.17.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.17.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.17.ln_2.weight', 'vision_encoder.transformer.resblocks.17.ln_2.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.17.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_1.weight', 'vision_encoder.transformer.resblocks.18.ln_1.bias', 'vision_encoder.transformer.resblocks.18.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.18.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.18.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.18.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.18.ln_2.weight', 'vision_encoder.transformer.resblocks.18.ln_2.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.18.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_1.weight', 'vision_encoder.transformer.resblocks.19.ln_1.bias', 'vision_encoder.transformer.resblocks.19.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.19.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.19.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.19.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.19.ln_2.weight', 'vision_encoder.transformer.resblocks.19.ln_2.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.19.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_1.weight', 'vision_encoder.transformer.resblocks.20.ln_1.bias', 'vision_encoder.transformer.resblocks.20.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.20.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.20.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.20.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.20.ln_2.weight', 'vision_encoder.transformer.resblocks.20.ln_2.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.20.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_1.weight', 'vision_encoder.transformer.resblocks.21.ln_1.bias', 'vision_encoder.transformer.resblocks.21.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.21.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.21.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.21.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.21.ln_2.weight', 'vision_encoder.transformer.resblocks.21.ln_2.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.21.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_1.weight', 'vision_encoder.transformer.resblocks.22.ln_1.bias', 'vision_encoder.transformer.resblocks.22.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.22.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.22.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.22.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.22.ln_2.weight', 'vision_encoder.transformer.resblocks.22.ln_2.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.22.mlp.c_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_1.weight', 'vision_encoder.transformer.resblocks.23.ln_1.bias', 'vision_encoder.transformer.resblocks.23.attn.in_proj_weight', 'vision_encoder.transformer.resblocks.23.attn.in_proj_bias', 'vision_encoder.transformer.resblocks.23.attn.out_proj.weight', 'vision_encoder.transformer.resblocks.23.attn.out_proj.bias', 'vision_encoder.transformer.resblocks.23.ln_2.weight', 'vision_encoder.transformer.resblocks.23.ln_2.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_fc.bias', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.weight', 'vision_encoder.transformer.resblocks.23.mlp.c_proj.bias', 'vision_encoder.ln_post.weight', 'vision_encoder.ln_post.bias', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.0.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.1.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.2.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.3.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.4.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.5.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.6.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.7.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.8.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.9.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.10.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.11.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.12.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.13.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.14.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.15.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.16.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.17.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.18.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.19.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.20.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.21.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.22.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.23.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.24.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.25.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.26.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.27.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.28.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.29.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.30.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_1.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.Wqkv.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.attn.out_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.norm_2.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.up_proj.weight', 'lang_encoder.transformer.blocks.31.decoder_layer.ffn.down_proj.weight', 'lang_encoder.transformer.norm_f.weight', 'lang_encoder.old_decoder_blocks.0.norm_1.weight', 'lang_encoder.old_decoder_blocks.0.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.0.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.0.norm_2.weight', 'lang_encoder.old_decoder_blocks.0.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.0.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_1.weight', 'lang_encoder.old_decoder_blocks.1.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.1.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.1.norm_2.weight', 'lang_encoder.old_decoder_blocks.1.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.1.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_1.weight', 'lang_encoder.old_decoder_blocks.2.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.2.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.2.norm_2.weight', 'lang_encoder.old_decoder_blocks.2.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.2.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_1.weight', 'lang_encoder.old_decoder_blocks.3.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.3.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.3.norm_2.weight', 'lang_encoder.old_decoder_blocks.3.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.3.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_1.weight', 'lang_encoder.old_decoder_blocks.4.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.4.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.4.norm_2.weight', 'lang_encoder.old_decoder_blocks.4.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.4.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_1.weight', 'lang_encoder.old_decoder_blocks.5.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.5.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.5.norm_2.weight', 'lang_encoder.old_decoder_blocks.5.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.5.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_1.weight', 'lang_encoder.old_decoder_blocks.6.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.6.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.6.norm_2.weight', 'lang_encoder.old_decoder_blocks.6.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.6.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_1.weight', 'lang_encoder.old_decoder_blocks.7.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.7.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.7.norm_2.weight', 'lang_encoder.old_decoder_blocks.7.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.7.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_1.weight', 'lang_encoder.old_decoder_blocks.8.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.8.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.8.norm_2.weight', 'lang_encoder.old_decoder_blocks.8.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.8.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_1.weight', 'lang_encoder.old_decoder_blocks.9.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.9.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.9.norm_2.weight', 'lang_encoder.old_decoder_blocks.9.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.9.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_1.weight', 'lang_encoder.old_decoder_blocks.10.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.10.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.10.norm_2.weight', 'lang_encoder.old_decoder_blocks.10.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.10.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_1.weight', 'lang_encoder.old_decoder_blocks.11.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.11.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.11.norm_2.weight', 'lang_encoder.old_decoder_blocks.11.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.11.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_1.weight', 'lang_encoder.old_decoder_blocks.12.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.12.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.12.norm_2.weight', 'lang_encoder.old_decoder_blocks.12.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.12.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_1.weight', 'lang_encoder.old_decoder_blocks.13.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.13.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.13.norm_2.weight', 'lang_encoder.old_decoder_blocks.13.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.13.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_1.weight', 'lang_encoder.old_decoder_blocks.14.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.14.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.14.norm_2.weight', 'lang_encoder.old_decoder_blocks.14.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.14.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_1.weight', 'lang_encoder.old_decoder_blocks.15.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.15.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.15.norm_2.weight', 'lang_encoder.old_decoder_blocks.15.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.15.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_1.weight', 'lang_encoder.old_decoder_blocks.16.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.16.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.16.norm_2.weight', 'lang_encoder.old_decoder_blocks.16.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.16.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_1.weight', 'lang_encoder.old_decoder_blocks.17.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.17.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.17.norm_2.weight', 'lang_encoder.old_decoder_blocks.17.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.17.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_1.weight', 'lang_encoder.old_decoder_blocks.18.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.18.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.18.norm_2.weight', 'lang_encoder.old_decoder_blocks.18.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.18.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_1.weight', 'lang_encoder.old_decoder_blocks.19.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.19.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.19.norm_2.weight', 'lang_encoder.old_decoder_blocks.19.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.19.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_1.weight', 'lang_encoder.old_decoder_blocks.20.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.20.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.20.norm_2.weight', 'lang_encoder.old_decoder_blocks.20.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.20.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_1.weight', 'lang_encoder.old_decoder_blocks.21.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.21.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.21.norm_2.weight', 'lang_encoder.old_decoder_blocks.21.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.21.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_1.weight', 'lang_encoder.old_decoder_blocks.22.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.22.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.22.norm_2.weight', 'lang_encoder.old_decoder_blocks.22.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.22.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_1.weight', 'lang_encoder.old_decoder_blocks.23.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.23.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.23.norm_2.weight', 'lang_encoder.old_decoder_blocks.23.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.23.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_1.weight', 'lang_encoder.old_decoder_blocks.24.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.24.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.24.norm_2.weight', 'lang_encoder.old_decoder_blocks.24.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.24.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_1.weight', 'lang_encoder.old_decoder_blocks.25.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.25.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.25.norm_2.weight', 'lang_encoder.old_decoder_blocks.25.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.25.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_1.weight', 'lang_encoder.old_decoder_blocks.26.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.26.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.26.norm_2.weight', 'lang_encoder.old_decoder_blocks.26.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.26.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_1.weight', 'lang_encoder.old_decoder_blocks.27.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.27.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.27.norm_2.weight', 'lang_encoder.old_decoder_blocks.27.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.27.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_1.weight', 'lang_encoder.old_decoder_blocks.28.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.28.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.28.norm_2.weight', 'lang_encoder.old_decoder_blocks.28.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.28.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_1.weight', 'lang_encoder.old_decoder_blocks.29.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.29.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.29.norm_2.weight', 'lang_encoder.old_decoder_blocks.29.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.29.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_1.weight', 'lang_encoder.old_decoder_blocks.30.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.30.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.30.norm_2.weight', 'lang_encoder.old_decoder_blocks.30.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.30.ffn.down_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_1.weight', 'lang_encoder.old_decoder_blocks.31.attn.Wqkv.weight', 'lang_encoder.old_decoder_blocks.31.attn.out_proj.weight', 'lang_encoder.old_decoder_blocks.31.norm_2.weight', 'lang_encoder.old_decoder_blocks.31.ffn.up_proj.weight', 'lang_encoder.old_decoder_blocks.31.ffn.down_proj.weight', 'lang_encoder.gated_cross_attn_layers.3.attn_gate', 'lang_encoder.gated_cross_attn_layers.3.ff_gate', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.3.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.3.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.3.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.3.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.7.attn_gate', 'lang_encoder.gated_cross_attn_layers.7.ff_gate', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.7.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.7.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.7.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.7.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.11.attn_gate', 'lang_encoder.gated_cross_attn_layers.11.ff_gate', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.11.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.11.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.11.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.11.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.15.attn_gate', 'lang_encoder.gated_cross_attn_layers.15.ff_gate', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.15.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.15.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.15.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.15.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.19.attn_gate', 'lang_encoder.gated_cross_attn_layers.19.ff_gate', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.19.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.19.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.19.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.19.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.23.attn_gate', 'lang_encoder.gated_cross_attn_layers.23.ff_gate', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.23.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.23.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.23.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.23.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.27.attn_gate', 'lang_encoder.gated_cross_attn_layers.27.ff_gate', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.27.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.27.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.27.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.27.ff.3.weight', 'lang_encoder.gated_cross_attn_layers.31.attn_gate', 'lang_encoder.gated_cross_attn_layers.31.ff_gate', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.norm.bias', 'lang_encoder.gated_cross_attn_layers.31.attn.to_q.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_kv.weight', 'lang_encoder.gated_cross_attn_layers.31.attn.to_out.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.0.bias', 'lang_encoder.gated_cross_attn_layers.31.ff.1.weight', 'lang_encoder.gated_cross_attn_layers.31.ff.3.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab model checkpoint from huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flamingo(\n",
       "  (vision_encoder): VisionTransformer(\n",
       "    (patchnorm_pre_ln): Identity()\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-23): 24 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (perceiver): PerceiverResampler(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PerceiverAttention(\n",
       "          (norm_media): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_latents): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lang_encoder): MPTForCausalLM(\n",
       "    (transformer): MPTModel(\n",
       "      (wte): Embedding(50280, 4096)\n",
       "      (emb_drop): Dropout(p=0, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4-6): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8-10): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12-14): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16-18): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20-22): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (24-26): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (27): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (28-30): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (31): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (old_decoder_blocks): ModuleList(\n",
       "      (0-31): 32 x MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (gated_cross_attn_layers): ModuleList(\n",
       "      (0-2): 3 x None\n",
       "      (3): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4-6): 3 x None\n",
       "      (7): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (8-10): 3 x None\n",
       "      (11): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x None\n",
       "      (15): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (16-18): 3 x None\n",
       "      (19): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (20-22): 3 x None\n",
       "      (23): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (24-26): 3 x None\n",
       "      (27): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (28-30): 3 x None\n",
       "      (31): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'definite': 16, 'ambiguous': 16})\n",
      "The question of <image> is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous <|endofchunk|>The question of <image> is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>The question of <image> is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite <|endofchunk|>\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"./ambiguous_questions_train.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_lines = [line for line in reader]\n",
    "\n",
    "\n",
    "with open(\"./ambiguous_questions_test.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_lines = [line for line in reader]\n",
    "    \n",
    "    \n",
    "  \n",
    "num_few_shot_examples = 32\n",
    "#promt = f\"Instructions : Classify the following into ambigous and definite question. An ambiguous question is unanswerable question considering image. \"\n",
    "\n",
    "few_shot_image_ids = [train_lines[idx][5] for idx in range(1,num_few_shot_examples + 1)]\n",
    "few_shot_images = [Image.open(\"./images/\" + str(image_id) + \".jpg\").convert('RGB') for image_id in few_shot_image_ids]\n",
    "\n",
    "vision_x = [image_processor(demo_image).unsqueeze(0) for demo_image in few_shot_images]\n",
    "\n",
    "labels = [\"ambiguous\" if train_lines[idx][6] == \"O\" else \"definite\" for idx in range(1, 101)]\n",
    "\n",
    "few_shot_examples_ids = []\n",
    "counter_list = []\n",
    "a_count = 0\n",
    "d_count = 0\n",
    "for idx, label in enumerate(labels):\n",
    "    if a_count + d_count == num_few_shot_examples:\n",
    "        break\n",
    "    \n",
    "    if label == \"ambiguous\":\n",
    "        if a_count < 16:\n",
    "            few_shot_examples_ids.append(idx)\n",
    "            a_count += 1\n",
    "            counter_list.append(label)\n",
    "    else:\n",
    "        \n",
    "        if d_count < 16:\n",
    "            few_shot_examples_ids.append(idx)\n",
    "            d_count += 1\n",
    "            \n",
    "            counter_list.append(label)\n",
    "            \n",
    "assert num_few_shot_examples == len(few_shot_examples_ids)\n",
    "\n",
    "print(Counter(counter_list))\n",
    "    \n",
    "\n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "\n",
    "text = [f\"The question of <image> is '{train_lines[idx+1][1]}'. Is the question is ambiguous or definite? Answer: {labels[idx]} <|endofchunk|>\"  for idx in few_shot_examples_ids]\n",
    "text = \"\".join(text)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/envs/torch2.0/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "2it [00:11,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Is the meat on top of the egg grilled or raw?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the meat on top of the egg grilled or raw?'. Is the question is ambiguous or definite? Answer: ambiguous \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "3it [00:21,  7.57s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What kind of food is on the plate that is to the left of the tray?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What kind of food is on the plate that is to the left of the tray?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:31,  8.52s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the vegetable to the right of the box the banana is to the left of?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the vegetable to the right of the box the banana is to the left of?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:41,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the fruit to the left of the banana that is on the table?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the fruit to the left of the banana that is on the table?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:52,  9.49s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What are the towels on, a chair or a shelf?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the towels on, a chair or a shelf?'. Is the question is ambiguous or definite? Answer: ambiguous \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:02,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Is the blue vehicle to the left or to the right of the van on the right of the photo?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the blue vehicle to the left or to the right of the van on the right of the photo?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:12,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What kind of vehicle is to the right of the woman that is to the right of the people?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What kind of vehicle is to the right of the woman that is to the right of the people?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:23, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  How big is the boat on the left?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'How big is the boat on the left?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:33, 10.21s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Does the man near the bag buy the apples in the middle?\n",
      "Generated text:  The question of  is 'Is the pillowcase to the right of the white thing that is to the right of the lamp?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the traffic cone to the left of the bicycle that is lying in the gravel?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Which color is the train the railroad contains?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the kneeling man holding a phone?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Are the chairs in the bottom or in the top part of the photo?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the vegetable to the left of the sausage smooth and red?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the grass that is not short tall or short?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Which piece of clothing is not striped, the cap or the shirt?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the man to the left or to the right of the girl that the chair is to the right of?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What kind of furniture is to the left of the magazine which is sitting on the table?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the left or to the right of the woman that is walking on the sidewalk?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the man to the left of the palm hold a cup?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What are the fruits that are to the right of the bowl the fruit is in?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color is the chair in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the long grass growing behind a giraffe?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the person to the right of the umpire doing?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is covering the cow that is standing near the fence?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'In which part is the bottle?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What is the color of the chair to the right of the man?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Is the cherry in the bottom or in the top part of the image?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'Does the bag that is not little look white?'. Is the question is ambiguous or definite? Answer: ambiguous The question of  is 'What color are the pants the lady is wearing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What color is the bike in the middle?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the police officer on the motorcycle the car is to the right of?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Who wears a hat?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'What is the name of the vegetable on the plate in the bottom part of the image?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left or to the right of the skis that look orange?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the man to the right of the car standing on a bus?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the white car to the left or to the right of the people on the right of the picture?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Where is the giraffe near the palm tree facing?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Is the woman to the left of the person that is wearing a shirt?'. Is the question is ambiguous or definite? Answer: definite The question of  is 'Does the man near the bag buy the apples in the middle?'. Is the question is ambiguous or definite? Answer: definite \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [01:44, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "12it [01:54, 10.33s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "13it [02:05, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "14it [02:15, 10.38s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "15it [02:25, 10.39s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "16it [02:36, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "17it [02:46, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "18it [02:57, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "19it [03:07, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "20it [03:18, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "21it [03:28, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "22it [03:38, 10.41s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "23it [03:49, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "24it [03:59, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "25it [04:10, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "26it [04:20, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "27it [04:30, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "28it [04:41, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "29it [04:51, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "30it [05:02, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "31it [05:12, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "32it [05:23, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "33it [05:33, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "34it [05:43, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "35it [05:54, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "36it [06:04, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "37it [06:15, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "38it [06:25, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "39it [06:36, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "40it [06:46, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "41it [06:57, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "42it [07:07, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "43it [07:17, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "44it [07:28, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "45it [07:38, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "46it [07:49, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "47it [07:59, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "48it [08:10, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "49it [08:20, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "50it [08:30, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "51it [08:41, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "52it [08:51, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "53it [09:02, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "54it [09:12, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "55it [09:22, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "56it [09:33, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "57it [09:43, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "58it [09:54, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "59it [10:04, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "60it [10:15, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "61it [10:25, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "62it [10:36, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "63it [10:46, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "64it [10:56, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "65it [11:07, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "66it [11:17, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "67it [11:28, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "68it [11:38, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "69it [11:49, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "70it [11:59, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "71it [12:09, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "72it [12:20, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "73it [12:30, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "74it [12:41, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "75it [12:51, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "76it [13:02, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "77it [13:12, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "78it [13:23, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "79it [13:33, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "80it [13:44, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "81it [13:54, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "82it [14:04, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "83it [14:15, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "84it [14:25, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "85it [14:36, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "86it [14:46, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "87it [14:57, 10.43s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "88it [15:07, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "89it [15:17, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "90it [15:28, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "91it [15:38, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "92it [15:49, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "93it [15:59, 10.45s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "94it [16:10, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "95it [16:20, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "96it [16:31, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "97it [16:41, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "98it [16:51, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "99it [17:02, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "100it [17:12, 10.44s/it]Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n",
      "101it [17:23, 10.33s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for idx, line in tqdm(enumerate(test_lines)):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    question = line[1]\n",
    "    image_id = line[5]\n",
    "    image = Image.open(\"./images/\" + str(image_id) + '.jpg').convert('RGB')\n",
    "    input_prompt = text + f\"The question of <image> is '{question}'. Is the question is ambiguous or definite? Answer:\"\n",
    "    \n",
    "    # print(input_prompt)\n",
    "    \n",
    "    input_images = vision_x + [image]\n",
    "    input_images = torch.cat(vision_x, dim=0)\n",
    "    input_images = input_images.unsqueeze(1).unsqueeze(0)\n",
    "    \n",
    "    lang_x = tokenizer(\n",
    "        [input_prompt] ,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    generated_text = model.generate(\n",
    "    vision_x=input_images.to(device),\n",
    "    lang_x=lang_x[\"input_ids\"].to(device),\n",
    "    attention_mask=lang_x[\"attention_mask\"].to(device),\n",
    "    max_new_tokens=2,\n",
    "    num_beams=4,\n",
    "    )\n",
    "    \n",
    "    #print(tokenizer.batch_decode(lang_x[\"input_ids\"],skip_special_tokens=False))\n",
    "    #print(\"Input prompt: \", input_prompt)\n",
    "    \n",
    "    decoded_text =  tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    if idx < 10:\n",
    "        print(\"question: \", question)\n",
    "        print(\"Generated text: \",decoded_text)\n",
    "        \n",
    "    answer = decoded_text.split(\"Answer:\")[-1].strip()\n",
    "\n",
    "    #inputs = processor(image, input_promt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    #out = model.generate(**inputs)\n",
    "    #prediction = processor.decode(out[0], skip_special_tokens=True)\n",
    "    #print(prediction)\n",
    "    predictions.append(answer)\n",
    "    \n",
    "with open (\"./test_fewshot_flamingo_balance.csv\", 'w') as f:\n",
    "        \n",
    "    writer = csv.writer(f)\n",
    "    for idx, line in enumerate(test_lines):\n",
    "        if idx == 0:\n",
    "            writer.writerow(line)\n",
    "        else:\n",
    "            line.append(predictions[idx-1])\n",
    "            writer.writerow(line)\n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
