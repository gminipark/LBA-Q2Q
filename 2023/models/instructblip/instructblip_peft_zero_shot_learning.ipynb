{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023-present the HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'Salesforce/instructblip-flan-t5-xxl'\n",
    "cache_dir = \"./\" + model_name_or_path.split('/')[-1]\n",
    "\n",
    "# We load our model and processor using `transformers`\n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path,cache_dir=cache_dir)\n",
    "model = AutoModelForVision2Seq.from_pretrained(model_name_or_path,cache_dir=cache_dir,torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "few_shot_examples = {}\n",
    "\n",
    "intermediate_questions =  pd.read_excel(\"intermediate_questions_samples_32.xlsx\", dtype={'qid' : str})\n",
    "\n",
    "with open(\"./ambiguous_questions_rebuilt_ptb.json\") as f:\n",
    "    ambiguous_questions = json.load(f)\n",
    "\n",
    "with open(\"./ambiguous_questions.json\") as f:\n",
    "    original_questions = json.load(f)\n",
    "\n",
    "print(len(ambiguous_questions))\n",
    "for idx in intermediate_questions.index:\n",
    "    intermediate_question_example = intermediate_questions.iloc[idx]\n",
    "    qid = intermediate_question_example['qid']\n",
    "\n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    \n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    intermediate_question = intermediate_question_example['intermediate question']\n",
    "    original_question_example = original_questions.pop(qid)\n",
    "    \n",
    "    few_shot_examples[qid] = original_question_example\n",
    "    few_shot_examples[qid]['ambiguous_question'] = ambiguous_question\n",
    "    few_shot_examples[qid]['intermediate_question'] = intermediate_question\n",
    "    few_shot_examples[qid].pop(\"addtional_question\")\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in few_shot_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in few_shot_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    few_shot_examples[qid]['question_entities'] = list(entities_list)\n",
    "   \n",
    "np.random.seed(42) \n",
    "test_keys = np.random.choice(list(original_questions.keys()), 32, replace=False)\n",
    "test_examples = {}\n",
    "\n",
    "for qid in test_keys:\n",
    "    original_questions[qid].pop(\"addtional_question\")\n",
    "    test_examples[qid] =  original_questions[qid]\n",
    "    \n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    \n",
    "    test_examples[qid][\"ambiguous_question\"] = ambiguous_question\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in test_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in test_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    test_examples[qid]['question_entities'] = list(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "promt = f\"Instructions : Classify the following into ambigous and definite question. An ambiguous question is unanswerable question considering image. \"\n",
    "text = \"\"\n",
    "\n",
    "predictions = []\n",
    "csv_lines = [[\"AQ\", \"IQ\"]]\n",
    "for idx,(qid, example) in tqdm(enumerate(test_examples.items())):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    question = example[\"ambiguous_question\"]\n",
    "    image_id = example['imageId']\n",
    "    image = Image.open(\"./images/\" + str(image_id) + '.jpg').convert('RGB')\n",
    "    \n",
    "    input_prompt = text + \\\n",
    "    f\"Main question is {example['ambiguous_question']} \" +  \\\n",
    "    \"The ambiguous entities of the main question: \" +  \" \".join(example['question_entities']) + \". \" + \\\n",
    "    \"Write a intermediate question to clarify the ambiguous entities of the main question. \" + \\\n",
    "    f\"Question: \"\n",
    "\n",
    "    # \"the intermediate question is not same with the main question.\" + \\\n",
    "    \n",
    "    \n",
    "    print(input_prompt)\n",
    "    inputs = processor(image, input_prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    out = model.generate(**inputs,\n",
    "                         do_sample=False,\n",
    "                        num_beams=5,\n",
    "                        max_length=256,\n",
    "                        min_length=3,\n",
    "                        top_p=0.9,\n",
    "                        repetition_penalty=1.5,\n",
    "                        length_penalty=1.0,\n",
    "                        temperature=1,)\n",
    "    prediction = processor.decode(out[0], skip_special_tokens=True)\n",
    "    example['intermediate_question'] = prediction\n",
    "    print(prediction)\n",
    "    predictions.append(prediction)\n",
    "    csv_lines.append([question, prediction])\n",
    "    \n",
    "with open (f\"./test_fewshot_{model_name_or_path.split('/')[-1]}.json\" , 'w') as f:\n",
    "     \n",
    "    json.dump(test_examples, f)   \n",
    "    # writer = csv.writer(f)\n",
    "    # for idx, line in enumerate(test_lines):\n",
    "    #     if idx == 0:\n",
    "    #         writer.writerow(line)\n",
    "    #     else:\n",
    "    #         line.append(predictions[idx-1])\n",
    "    #         writer.writerow(line)\n",
    "\n",
    "with open (f\"./test_fewshot_{model_name_or_path.split('/')[-1]}.csv\" , 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(csv_lines)       \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
