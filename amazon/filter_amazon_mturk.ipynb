{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "is_clean = False\n",
    "target_file = \"batch_results_4000.csv\"\n",
    "\n",
    "clean_csv_file = []\n",
    "same_tag_list = []\n",
    "diff_tag_list = []\n",
    "with open(target_file, 'r') as f:\n",
    "    df = pd.read_csv(f)\n",
    "    clean_df = pd.DataFrame()\n",
    "    \n",
    "    if is_clean:\n",
    "        clean_df = df\n",
    "        if 'labels' not in clean_df.keys():\n",
    "            clean_df = clean_df.rename(columns={\"effectiveness\" : \"labels\"})\n",
    "    \n",
    "    else:\n",
    "        for key in df.keys():\n",
    "            if \"Input.\" in key:\n",
    "                new_key = key.split('Input.')[-1]\n",
    "                clean_df[new_key] = df[key]\n",
    "            \n",
    "            if \"Answer\" in key:\n",
    "                clean_df[\"labels\"] = df[key] \n",
    "\n",
    "    for idx in range(len(clean_df)):\n",
    "        line = clean_df.iloc[idx]\n",
    "        \n",
    "        line_dict = line.to_dict()\n",
    "        line_dict['labels'] = 'O' if line_dict['labels']=='[{\"effectiveness\":\"yes\"}]' or line_dict['labels'] == 'O' else 'X'\n",
    "        \n",
    "        found = False\n",
    "        for sample in samples:\n",
    "            if sample['q_id'] == line_dict['q_id'] and sample['intermediate_question'] == line_dict['intermediate_question']:\n",
    "                found=True\n",
    "                if sample['labels'] == line_dict['labels']:\n",
    "                    same_tag_list.append(line_dict)\n",
    "                else:\n",
    "                    diff_tag_list.append(sample)\n",
    "                    diff_tag_list.append(line_dict)\n",
    "        if not found:\n",
    "            samples.append(line_dict)\n",
    "            \n",
    "print(len(clean_df))\n",
    "print(len(same_tag_list))\n",
    "print(len(diff_tag_list) / 2)\n",
    "\n",
    "assert len(same_tag_list) * 2 + len(diff_tag_list) == len(clean_df)\n",
    "\n",
    "same_df = pd.DataFrame(same_tag_list)\n",
    "diff_df = pd.DataFrame(diff_tag_list)\n",
    "\n",
    "file_name = Path(target_file).stem\n",
    "\n",
    "clean_df.sort_values(\"q_id\")\n",
    "same_df.sort_values(\"q_id\")\n",
    "diff_df.sort_values(\"q_id\")\n",
    "\n",
    "clean_df.to_csv(file_name+\"_clean.csv\",index=False)\n",
    "same_df.to_csv(file_name+\"_same.csv\",index=False)\n",
    "diff_df.to_csv(file_name+\"_diff.csv\",index=False)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    " \n",
    "print(Counter(same_df['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "csv_files = glob(\"*_results_*_same.csv\")\n",
    "\n",
    "split_unit = 200\n",
    "test_nums = 100\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={'train' : csv_files})\n",
    "dataset.shuffle(42)\n",
    "dataset = dataset['train'].train_test_split(test_size=test_nums)\n",
    "\n",
    "test_dict = dataset['test']\n",
    "test_dataset = pd.DataFrame(test_dict)\n",
    "test_dataset.to_csv(f\"test_{test_nums}_same.csv\", index=False)\n",
    "print(Counter(dataset['train']['labels']))\n",
    "print(Counter(test_dict['labels']))\n",
    "\n",
    "stop = False\n",
    "while(not stop):\n",
    "    train_dict = dataset['train'].sort('labels', reverse=True)[:split_unit]\n",
    "    train_dataset = pd.DataFrame(train_dict)\n",
    "    train_dataset.to_csv(f\"train_{split_unit}_same_bal.csv\", index=False)\n",
    "    split_unit = split_unit * 2\n",
    "    \n",
    "    if split_unit > len(dataset['train']) - test_nums:\n",
    "        stop = True\n",
    "    print(Counter(train_dict[\"labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "same_csv_files = glob(\"*_results_*_same.csv\")\n",
    "diff_csv_files = glob(\"*_results_*_diff.csv\")\n",
    "\n",
    "split_unit = 200\n",
    "test_nums = 100\n",
    "\n",
    "same_dataset = load_dataset(\"csv\", data_files={'train' : same_csv_files})\n",
    "diff_dataset = load_dataset(\"csv\", data_files={'train' : diff_csv_files})\n",
    "\n",
    "diff_dataset = diff_dataset.filter(lambda example: example['labels'] == \"X\")\n",
    "\n",
    "print(diff_dataset['train'])\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = concatenate_datasets([same_dataset['train'], diff_dataset['train']])\n",
    "print(dataset)\n",
    "dataset.shuffle(42)\n",
    "\n",
    "\n",
    "dataset = dataset['train'].train_test_split(test_size=test_nums)\n",
    "\n",
    "test_dict = dataset['test']\n",
    "test_dataset = pd.DataFrame(test_dict)\n",
    "test_dataset.to_csv(f\"test_{test_nums}_same_diff.csv\", index=False)\n",
    "print(Counter(dataset['train']['labels']))\n",
    "print(Counter(test_dict['labels']))\n",
    "\n",
    "stop = False\n",
    "while(not stop):\n",
    "    #train_dict = dataset['train'].sort('labels', reverse=True)[:split_unit]\n",
    "    train_dict = dataset['train'][:split_unit]\n",
    "    train_dataset = pd.DataFrame(train_dict)\n",
    "    train_dataset.to_csv(f\"train_{split_unit}_same_diff.csv\", index=False)\n",
    "    split_unit = split_unit * 2\n",
    "    \n",
    "    if split_unit > len(dataset['train']) - test_nums:\n",
    "        stop = True\n",
    "    print(Counter(train_dict[\"labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def augment_dataset(samples, augment_nums):\n",
    "    \n",
    "    new_samples = {}\n",
    "    print(len(samples['labels']))\n",
    "    for key in samples.keys():\n",
    "        for i in range(augment_nums):\n",
    "            if i == 0:\n",
    "                new_samples[key] = samples[key].copy()\n",
    "            else:\n",
    "                new_samples[key].extend(samples[key].copy())\n",
    "    \n",
    "    print(len(samples['labels']))\n",
    "    \n",
    "    return new_samples\n",
    "        \n",
    "        \n",
    "csv_files = glob(\"*_results_*_same.csv\")\n",
    "\n",
    "split_unit = 200\n",
    "test_nums = 100\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={'train' : csv_files})\n",
    "dataset.shuffle(42)\n",
    "\n",
    "dataset = dataset['train'].train_test_split(test_size=test_nums,seed=42)\n",
    "\n",
    "test_dict = dataset['test']\n",
    "test_dataset = pd.DataFrame(test_dict)\n",
    "test_dataset.to_csv(f\"test_{test_nums}_same.csv\", index=False)\n",
    "print(Counter(dataset['train']['labels']))\n",
    "print(Counter(test_dict['labels']))\n",
    "\n",
    "stop = False\n",
    "while(not stop):\n",
    "    \n",
    "    true_examples = dataset.filter(lambda example: example[\"labels\"] == \"O\",with_indices=False)['train']\n",
    "    false_examples = dataset.filter(lambda example: example[\"labels\"] == \"X\",with_indices=False)['train']\n",
    "    \n",
    "    if len(false_examples) < split_unit // 2:\n",
    "        \n",
    "        augment_nums = split_unit // 2 // len(false_examples)\n",
    "        \n",
    "        print(augment_nums)\n",
    "        augmented_examples = false_examples.map(augment_dataset ,batched=True ,fn_kwargs={'augment_nums':augment_nums},load_from_cache_file=False,keep_in_memory=False)\n",
    "        print(augmented_examples)\n",
    "        \n",
    "        false_examples=augmented_examples\n",
    "    \n",
    "\n",
    "    true_examples=true_examples.select(range(split_unit // 2))\n",
    "    if len(false_examples) >= (split_unit // 2):\n",
    "        false_examples=false_examples.select(range(split_unit // 2))\n",
    "    \n",
    "    train_dict = concatenate_datasets([true_examples, false_examples])    \n",
    "\n",
    "    train_dataset = pd.DataFrame(train_dict)\n",
    "    train_dataset.to_csv(f\"train_{split_unit}_same_balan.csv\", index=False)\n",
    "    split_unit = split_unit * 2\n",
    "    \n",
    "    if split_unit // 2  > len(dataset['train']):\n",
    "        stop = True\n",
    "    print(Counter(train_dict[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "def make_negative_samples(samples, intermediate_questions):\n",
    "    \n",
    "    total_negative_samples=[]\n",
    "    for idx, image_id in enumerate(samples['image_id']):\n",
    "        intermediate_questions_list = intermediate_questions[str(image_id)][str(samples['entity_id'][idx])]\n",
    "        negative_samples=[]\n",
    "        for intermediate_question in intermediate_questions_list:\n",
    "            if intermediate_question['label'] == \"negative\":\n",
    "                negative_sample = dict()\n",
    "                for key in samples.keys():\n",
    "                    negative_sample[key] = samples[key][idx]\n",
    "                \n",
    "                negative_sample['intermediate_question'] = intermediate_question['question']\n",
    "                negative_sample['intermediate_answer'] = intermediate_question['answer']\n",
    "                negative_sample['labels'] = \"X\"\n",
    "                negative_samples.append(negative_sample)\n",
    "        total_negative_samples.append(negative_samples)\n",
    "\n",
    "    return {\"data\" : total_negative_samples}\n",
    "\n",
    "\n",
    "def make_negative_dataset(positive_dataset, intermediate_questions):\n",
    "    #positive_dataset = DatasetDict({\"positive_samples\" : positive_dataset})\n",
    "    print(positive_dataset)\n",
    "    negative_dataset = positive_dataset.map(make_negative_samples, batched=True, fn_kwargs={\"intermediate_questions\" : intermediate_questions},)\n",
    "\n",
    "    ngative_samples_list = [sample for negative_samples in negative_dataset['data'] for sample in negative_samples]\n",
    "\n",
    "    df = pd.DataFrame(ngative_samples_list)\n",
    "    print(len(df))\n",
    "    unique_df = df.drop_duplicates()\n",
    "\n",
    "    negative_dataset = Dataset.from_pandas(unique_df,preserve_index=False)\n",
    "    \n",
    "    return negative_dataset\n",
    "\n",
    "\n",
    "# csv_files = glob(\"*_results_*_same.csv\")\n",
    "\n",
    "# dataset = load_dataset(\"csv\", data_files=csv_files)\n",
    "\n",
    "# print(dataset)\n",
    "\n",
    "# positive_dataset = dataset.filter(lambda example: example[\"labels\"] == \"O\",with_indices=False)\n",
    "\n",
    "# # with open(\"./sceneGraphs/train_sceneGraphs.json\") as f:\n",
    "# #     sceneGraphs = json.load(f)\n",
    "    \n",
    "# with open(\"./intermediate_questions.json\") as f:\n",
    "#     intermediate_questions = json.load(f)\n",
    "    \n",
    "# negative_dataset = make_negative_dataset(positive_dataset['train'], intermediate_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict, Dataset\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "csv_files = glob(\"*_results_*_same.csv\")\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={'train' : csv_files})\n",
    "dataset.shuffle(42)\n",
    "\n",
    "\n",
    "true_examples = dataset.filter(lambda example: example[\"labels\"] == \"O\",with_indices=False)['train']\n",
    "#print(true_examples)\n",
    "false_examples = dataset.filter(lambda example: example[\"labels\"] == \"X\",with_indices=False)['train']\n",
    "#print(len(false_examples))\n",
    "\n",
    "true_dataset = true_examples.train_test_split(test_size=len(false_examples),seed=42)\n",
    "false_dataset = DatasetDict()\n",
    "false_dataset['test'] = false_examples\n",
    "\n",
    "split_unit = 200\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset_list = [true_dataset, false_dataset]\n",
    "for key in true_dataset.keys():\n",
    "    dataset[key] = concatenate_datasets([target_dataset[key] for target_dataset in dataset_list if key in target_dataset.keys()])\n",
    "\n",
    "print(dataset)\n",
    "test_dict = dataset['test']\n",
    "test_nums = len(test_dict)\n",
    "test_dataset = pd.DataFrame(test_dict)\n",
    "test_dataset.to_csv(f\"test_{test_nums}_same.csv\", index=False)\n",
    "print(Counter(dataset['train']['labels']))\n",
    "print(Counter(test_dict['labels']))\n",
    "\n",
    "with open(\"./intermediate_questions.json\") as f:\n",
    "        intermediate_questions = json.load(f)\n",
    "\n",
    "stop = False\n",
    "while(not stop):\n",
    "\n",
    "    true_examples=dataset['train'].select(range(split_unit // 2))\n",
    "    \n",
    "    \n",
    "#     if len(false_examples) < split_unit // 2:\n",
    "        \n",
    "    augment_nums = split_unit // 2 // len(false_examples)\n",
    "    \n",
    "    print(augment_nums)\n",
    "    \n",
    "    negative_dataset = make_negative_dataset(true_examples, intermediate_questions)\n",
    "    \n",
    "    \n",
    "    false_examples=negative_dataset\n",
    "    \n",
    "\n",
    "    true_examples=true_examples.select(range(split_unit // 2))\n",
    "    if len(false_examples) >= (split_unit // 2):\n",
    "        false_examples=false_examples.select(range(split_unit // 2))\n",
    "    \n",
    "    train_dict = concatenate_datasets([true_examples, false_examples])    \n",
    "\n",
    "    train_dataset = pd.DataFrame(train_dict)\n",
    "    train_dataset.to_csv(f\"train_{split_unit}_same_aug.csv\", index=False)\n",
    "    split_unit = split_unit * 2\n",
    "    \n",
    "    if split_unit // 2  > len(dataset['train']):\n",
    "        stop = True\n",
    "    print(Counter(train_dict[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-46efa3dbe2e2ed37\n",
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9c87b339184abb91f1288bcd3769c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-f53819167acd19cb.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-087e50f2c97ea013.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d55add5ff94773c5.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-23ee211f5c46df7d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "        num_rows: 4401\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "        num_rows: 4401\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e73e8aaa14807544.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-9e9ceff586347892.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644\n",
      "Counter({'O': 4967, 'X': 361})\n",
      "Counter({'O': 200, 'X': 167})\n",
      "!!!!!!! Counter({'O': 200, 'X': 42})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a4e50a690e34aaca.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Counter({'O': 100, 'X': 64})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d6a76af49d9636af.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "Counter({'O': 200, 'X': 143})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-05a9e697c082fc97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "Counter({'O': 400, 'X': 233})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 800\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b9bbc0b04e729ac5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n",
      "Counter({'O': 800, 'X': 467})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 1600\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-20d33755545ff88c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927\n",
      "Counter({'O': 1600, 'X': 991})\n",
      "Dataset({\n",
      "    features: ['q_id', 'image_id', 'ambiguous_question', 'ambiguous_entity', 'intermediate_question', 'intermediate_answer', 'entity_id', 'labels'],\n",
      "    num_rows: 3200\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-46efa3dbe2e2ed37/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-efee60a1963dd056.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6528\n",
      "Counter({'O': 3200, 'X': 2169})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict, Dataset\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "import json\n",
    "\n",
    "csv_files = glob(\"*_results_*_same.csv\")\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={'train' : csv_files})\n",
    "dataset.shuffle(42)\n",
    "\n",
    "random.seed(42)\n",
    "true_examples = dataset.filter(lambda example: example[\"labels\"] == \"O\",with_indices=False)['train']\n",
    "#print(true_examples)\n",
    "#false_examples = dataset.filter(lambda example: example[\"labels\"] == \"X\",with_indices=False)['train']\n",
    "#print(len(false_examples))\n",
    "\n",
    "unique_image_ids = list(set(true_examples['image_id']))\n",
    "split_point = int(0.9 * len(unique_image_ids))\n",
    "train_image_ids = unique_image_ids[:split_point]\n",
    "test_image_ids = unique_image_ids[split_point:]\n",
    "\n",
    "train_dataset = true_examples.filter(lambda example: example[\"image_id\"]  in train_image_ids)\n",
    "test_dataset = true_examples.filter(lambda example: example[\"image_id\"]  in test_image_ids)\n",
    "\n",
    "test_true_size=200\n",
    "\n",
    "new_dataset = DatasetDict()\n",
    "new_dataset['train'] = train_dataset\n",
    "new_dataset['test'] = test_dataset.select(range(test_true_size))\n",
    "print(new_dataset)\n",
    "# true_dataset = true_examples.train_test_split(test_size=test_true_size,seed=42)\n",
    "# # false_dataset = DatasetDict()\n",
    "# # false_dataset['test'] = false_examples\n",
    "\n",
    "# print(true_dataset['test'][:10])\n",
    "\n",
    "split_unit = 200\n",
    "\n",
    "# dataset = true_dataset\n",
    "# # dataset = DatasetDict()\n",
    "# # dataset_list = [true_dataset, false_dataset]\n",
    "# # for key in true_dataset.keys():\n",
    "# #     dataset[key] = concatenate_datasets([target_dataset[key] for target_dataset in dataset_list if key in target_dataset.keys()])\n",
    "\n",
    "with open(\"./intermediate_questions.json\") as f:\n",
    "        intermediate_questions = json.load(f)\n",
    "\n",
    "print(new_dataset)\n",
    "test_dict = new_dataset['test']\n",
    "negative_dataset = make_negative_dataset(test_dict, intermediate_questions)\n",
    "if len(negative_dataset) > test_true_size:\n",
    "    negative_dataset = negative_dataset.select(random.sample(range(len(negative_dataset)),test_true_size))\n",
    "test_dict = concatenate_datasets([test_dict, negative_dataset])\n",
    "test_nums = len(test_dict)\n",
    "test_dataset = pd.DataFrame(test_dict)\n",
    "test_dataset.to_csv(f\"test_{test_nums}_same_true_v2.csv\", index=False)\n",
    "\n",
    "\n",
    "human_negative_dataset = dataset.filter(lambda example: example[\"labels\"] == \"X\" and example[\"image_id\"] in test_image_ids, with_indices=False)['train']\n",
    "human_test_dict = concatenate_datasets([new_dataset['test'], human_negative_dataset])\n",
    "human_test_dataset = pd.DataFrame(human_test_dict)\n",
    "human_test_nums = len(human_test_dict)\n",
    "human_test_dataset.to_csv(f\"test_{human_test_nums}_same_true_human.csv\", index=False)\n",
    "\n",
    "print(Counter(dataset['train']['labels']))\n",
    "print(Counter(test_dict['labels']))\n",
    "print(\"!!!!!!!\",Counter(human_test_dict['labels']))\n",
    "\n",
    "\n",
    "stop = False\n",
    "while(not stop):\n",
    "\n",
    "    true_examples=new_dataset['train'].select(range(split_unit // 2))\n",
    "    \n",
    "    \n",
    "#     if len(false_examples) < split_unit // 2:\n",
    "        \n",
    "    #augment_nums = split_unit // 2 // len(false_examples)\n",
    "    \n",
    "    #print(augment_nums)\n",
    "    \n",
    "    negative_dataset = make_negative_dataset(true_examples, intermediate_questions)\n",
    "    \n",
    "    \n",
    "    false_examples=negative_dataset\n",
    "    \n",
    "\n",
    "    # true_examples=true_examples.select(range(split_unit // 2))\n",
    "    if len(false_examples) >= (split_unit // 2):\n",
    "        false_examples=false_examples.select(random.sample(range(len(false_examples)),split_unit // 2))\n",
    "    \n",
    "    train_dict = concatenate_datasets([true_examples, false_examples])    \n",
    "\n",
    "    train_dataset = pd.DataFrame(train_dict)\n",
    "    train_dataset.to_csv(f\"train_{split_unit}_same_true_aug_v2.csv\", index=False)\n",
    "    split_unit = split_unit * 2\n",
    "    \n",
    "    if split_unit // 2  > len(dataset['train']):\n",
    "        stop = True\n",
    "    print(Counter(train_dict[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "results_files = glob(\"batch_results_*_*.csv\")\n",
    "\n",
    "total_samples = pd.read_csv(\"./intermediate_questions_samples.csv\")\n",
    "\n",
    "print(results_files)\n",
    "\n",
    "for file in results_files:\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        df = pd.read_csv(f)\n",
    "        #print(df.columns)\n",
    "        drop_list = list(filter(lambda x: \"Unnamed\" in x , df.columns))\n",
    "        #print(drop_list)\n",
    "        df = df.drop(labels=drop_list, axis=1)\n",
    "        #print(df.columns)\n",
    "        if 'entity_id' in df:\n",
    "            pass\n",
    "        else:\n",
    "            df['entity_id'] = None\n",
    "            for idx, sample in tqdm(df.iterrows(), total=len(df)):\n",
    "                same_sample = total_samples.loc[(total_samples['q_id']==sample['q_id']) & (total_samples['intermediate_question']==sample['intermediate_question'])]    \n",
    "                #print(same_sample)\n",
    "                \n",
    "                df.loc[idx,'entity_id']  =  same_sample['entity_id'].iloc[0]\n",
    "                #$\n",
    "            #print(df[:10])\n",
    "        df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
