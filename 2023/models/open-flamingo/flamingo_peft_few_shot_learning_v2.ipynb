{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023-present the HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "few_shot_examples = {}\n",
    "\n",
    "intermediate_questions =  pd.read_excel(\"intermediate_questions_samples_32.xlsx\", dtype={'qid' : str})\n",
    "\n",
    "with open(\"./ambiguous_questions_rebuilt_ptb.json\") as f:\n",
    "    ambiguous_questions = json.load(f)\n",
    "\n",
    "with open(\"./ambiguous_questions.json\") as f:\n",
    "    original_questions = json.load(f)\n",
    "\n",
    "print(len(ambiguous_questions))\n",
    "for idx in intermediate_questions.index:\n",
    "    intermediate_question_example = intermediate_questions.iloc[idx]\n",
    "    qid = intermediate_question_example['qid']\n",
    "\n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    \n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    intermediate_question = intermediate_question_example['intermediate question']\n",
    "    original_question_example = original_questions.pop(qid)\n",
    "    \n",
    "    few_shot_examples[qid] = original_question_example\n",
    "    few_shot_examples[qid]['ambiguous_question'] = ambiguous_question\n",
    "    few_shot_examples[qid]['intermediate_question'] = intermediate_question\n",
    "    few_shot_examples[qid].pop(\"addtional_question\")\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in few_shot_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in few_shot_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    few_shot_examples[qid]['question_entities'] = list(entities_list)\n",
    "   \n",
    "np.random.seed(42) \n",
    "test_keys = np.random.choice(list(original_questions.keys()), 32, replace=False)\n",
    "test_examples = {}\n",
    "\n",
    "for qid in test_keys:\n",
    "    original_questions[qid].pop(\"addtional_question\")\n",
    "    test_examples[qid] =  original_questions[qid]\n",
    "    \n",
    "    ambiguous_question_example = ambiguous_questions[qid]\n",
    "    ambiguous_question = ambiguous_question_example['question']\n",
    "    \n",
    "    test_examples[qid][\"ambiguous_question\"] = ambiguous_question\n",
    "    \n",
    "    entities_list = set()\n",
    "    for object_name in test_examples[qid]['irrelated_object_names'].values():\n",
    "        if object_name in test_examples[qid]['ambiguous_question']:\n",
    "             entities_list.add(object_name)\n",
    "    test_examples[qid]['question_entities'] = list(entities_list)\n",
    "    \n",
    "# dataset = load_dataset(\"csv\", data_files={\"train\" : \"./ambiguous_questions_train.csv\", \"test\" : \"./ambiguous_questions_test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_flamingo import create_model_and_transforms\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "    cross_attn_every_n_layers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab model checkpoint from huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "num_few_shot_examples = len(few_shot_examples)\n",
    "\n",
    "few_shot_image_ids = [example[\"imageId\"] for example in few_shot_examples.values()]\n",
    "few_shot_images = [Image.open(\"./images/\" + str(image_id) + \".jpg\").convert('RGB') for image_id in few_shot_image_ids]\n",
    "\n",
    "vision_x = [image_processor(demo_image).unsqueeze(0) for demo_image in few_shot_images]\n",
    "                \n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "\n",
    "text = [f\"<image>Main question is {few_shot_example['ambiguous_question']}. \" +   \n",
    "        \"Write a intermediate question to clarify entities of the main question. \" + \n",
    "        f\"Intermediate question: {few_shot_example['intermediate_question']} <|endofchunk|>\"  for qid, few_shot_example in few_shot_examples.items()]\n",
    "\n",
    "        # \"The entitites of question: \" +  \" \".join(few_shot_example['question_entities']) + \". \" + \n",
    "        \n",
    "\n",
    "text = \"\".join(text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for idx, (qid, example)in tqdm(enumerate(test_examples.items())):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    question = example[\"ambiguous_question\"]\n",
    "    image_id = example['imageId']\n",
    "    image = Image.open(\"./images/\" + str(image_id) + '.jpg').convert('RGB')\n",
    "    input_prompt = text + \\\n",
    "    f\"<image>Main question is {example['ambiguous_question']}. \" +  \\\n",
    "    \"Write a intermediate question to clarify entities of the main question. \" + \\\n",
    "    f\"Intermediate question: \"\n",
    "    \n",
    "    input_images = vision_x + [image]\n",
    "    input_images = torch.cat(vision_x, dim=0)\n",
    "    input_images = input_images.unsqueeze(1).unsqueeze(0)\n",
    "    \n",
    "    lang_x = tokenizer(\n",
    "        [input_prompt] ,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    generated_text = model.generate(\n",
    "    vision_x=input_images.to(device),\n",
    "    lang_x=lang_x[\"input_ids\"].to(device),\n",
    "    attention_mask=lang_x[\"attention_mask\"].to(device),\n",
    "    max_new_tokens=20,\n",
    "    num_beams=3,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    decoded_text =  tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    if idx < 5:\n",
    "        print(\"question: \", question)\n",
    "        print(\"Generated text: \",decoded_text.split(\"Intermediate question:\")[-1].strip())\n",
    "        # print()\n",
    "    intermediate_question = decoded_text.split(\"Intermediate question:\")[-1].strip()\n",
    "\n",
    "\n",
    "    predictions.append(intermediate_question)\n",
    "    \n",
    "\n",
    "print(predictions)\n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (qid, example)in tqdm(enumerate(test_examples.items())):\n",
    "    print(example['ambiguous_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
