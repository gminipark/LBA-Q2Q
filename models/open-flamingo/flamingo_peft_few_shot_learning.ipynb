{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2023-present the HuggingFace Inc. team.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\" : \"./ambiguous_questions_train.csv\", \"test\" : \"./ambiguous_questions_test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_flamingo import create_model_and_transforms\n",
    "\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path=\"ViT-L-14\",\n",
    "    clip_vision_encoder_pretrained=\"openai\",\n",
    "    lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "    tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "    cross_attn_every_n_layers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab model checkpoint from huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"./ambiguous_questions_train.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_lines = [line for line in reader]\n",
    "\n",
    "\n",
    "with open(\"./ambiguous_questions_test.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_lines = [line for line in reader]\n",
    "    \n",
    "    \n",
    "  \n",
    "num_few_shot_examples = 32\n",
    "#promt = f\"Instructions : Classify the following into ambigous and definite question. An ambiguous question is unanswerable question considering image. \"\n",
    "\n",
    "few_shot_image_ids = [train_lines[idx][5] for idx in range(1,num_few_shot_examples + 1)]\n",
    "few_shot_images = [Image.open(\"./images/\" + str(image_id) + \".jpg\").convert('RGB') for image_id in few_shot_image_ids]\n",
    "\n",
    "vision_x = [image_processor(demo_image).unsqueeze(0) for demo_image in few_shot_images]\n",
    "\n",
    "labels = [\"ambiguous\" if train_lines[idx][6] == \"O\" else \"definite\" for idx in range(1, 101)]\n",
    "\n",
    "few_shot_examples_ids = []\n",
    "counter_list = []\n",
    "a_count = 0\n",
    "d_count = 0\n",
    "for idx, label in enumerate(labels):\n",
    "    if a_count + d_count == num_few_shot_examples:\n",
    "        break\n",
    "    \n",
    "    if label == \"ambiguous\":\n",
    "        if a_count < 16:\n",
    "            few_shot_examples_ids.append(idx)\n",
    "            a_count += 1\n",
    "            counter_list.append(label)\n",
    "    else:\n",
    "        \n",
    "        if d_count < 16:\n",
    "            few_shot_examples_ids.append(idx)\n",
    "            d_count += 1\n",
    "            \n",
    "            counter_list.append(label)\n",
    "            \n",
    "assert num_few_shot_examples == len(few_shot_examples_ids)\n",
    "\n",
    "print(Counter(counter_list))\n",
    "    \n",
    "\n",
    "tokenizer.padding_side = \"left\" # For generation padding tokens should be on the left\n",
    "\n",
    "text = [f\"The question of <image> is '{train_lines[idx+1][1]}'. Is the question is ambiguous or definite? Answer: {labels[idx]} <|endofchunk|>\"  for idx in few_shot_examples_ids]\n",
    "text = \"\".join(text)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for idx, line in tqdm(enumerate(test_lines)):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    question = line[1]\n",
    "    image_id = line[5]\n",
    "    image = Image.open(\"./images/\" + str(image_id) + '.jpg').convert('RGB')\n",
    "    input_prompt = text + f\"The question of <image> is '{question}'. Is the question is ambiguous or definite? Answer:\"\n",
    "    \n",
    "    # print(input_prompt)\n",
    "    \n",
    "    input_images = vision_x + [image]\n",
    "    input_images = torch.cat(vision_x, dim=0)\n",
    "    input_images = input_images.unsqueeze(1).unsqueeze(0)\n",
    "    \n",
    "    lang_x = tokenizer(\n",
    "        [input_prompt] ,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    generated_text = model.generate(\n",
    "    vision_x=input_images.to(device),\n",
    "    lang_x=lang_x[\"input_ids\"].to(device),\n",
    "    attention_mask=lang_x[\"attention_mask\"].to(device),\n",
    "    max_new_tokens=2,\n",
    "    num_beams=4,\n",
    "    )\n",
    "    \n",
    "    #print(tokenizer.batch_decode(lang_x[\"input_ids\"],skip_special_tokens=False))\n",
    "    #print(\"Input prompt: \", input_prompt)\n",
    "    \n",
    "    decoded_text =  tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    if idx < 10:\n",
    "        print(\"question: \", question)\n",
    "        print(\"Generated text: \",decoded_text)\n",
    "        \n",
    "    answer = decoded_text.split(\"Answer:\")[-1].strip()\n",
    "\n",
    "    #inputs = processor(image, input_promt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    #out = model.generate(**inputs)\n",
    "    #prediction = processor.decode(out[0], skip_special_tokens=True)\n",
    "    #print(prediction)\n",
    "    predictions.append(answer)\n",
    "    \n",
    "with open (\"./test_fewshot_flamingo_balance.csv\", 'w') as f:\n",
    "        \n",
    "    writer = csv.writer(f)\n",
    "    for idx, line in enumerate(test_lines):\n",
    "        if idx == 0:\n",
    "            writer.writerow(line)\n",
    "        else:\n",
    "            line.append(predictions[idx-1])\n",
    "            writer.writerow(line)\n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
